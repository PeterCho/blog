---
layout: post
title:  "Classifying Gender via a Convolutional Neural Network for Faces"
date:   2016-08-09 12:00:00
categories: Deep Learning
---

## Gender training data 

In our previous blog post, we localized faces within internet photos using
instance segmentation.  In this entry, we continue to accumulate and
investigate a sizable corpus of "faces in the wild".  But now our primary
focus is upon classifying rather than detecting faces.

Humans around the world may be described in terms of various
characteristics which can change on time scales ranging from seconds
(e.g. mood) to decades (e.g. age).  But for most people, gender labels are
constant throughout their lifetimes.  Moreover, physical differences exist
between male and female faces.  So we seek to build a classifer which can
identify gender based primarily upon face imagery input.

We begin by extending our dataset of internet images from our prior face
localization study.  We have collected 13740 images which intentionally
exhibit as much variety as possible.  2815 of the images originated from
the WIDER collection [ref], while the remaining pictures were manually
downloaded primarily from Google Images.  10492 photos in this corpus
contain 43752 human faces which were annotated with bounding boxes via
dlib's image labeling tool IMGLAB [ref].  The labeled faces belong to
people with differing attributes (e.g. gender, age, ethnicity) performing
varying activities (e.g. socializing, swimming, singing) in disparate
settings (e.g. hospital interiors, memorial services, sport stadiums).
Moreover, people's visages are oriented in variable poses (e.g. facing
camera, looking upwards, profile view), and many are partially occluded by
objects (e.g. eyeglasses, drinking cups, other people's heads).  We also
intentionally increased the number of internet images containing faces from
paintings and drawings from our previous face investigation.

While dlib's IMGLAB is convenient for drawing bounding boxes around
objects, it does not currently support hierarchical assignment of multiple
labels per box.  So we developed our own gender attribution tool based upon
the 3D graphics toolkit OpenSceneGraph [ref].  It imports and displays face
bounding boxes generated via IMGLAB. A user may press the "1", "2" or "0"
keys on the number pad to set gender attributes for all bounding boxes in
an image to male, female or unknown.  After a particular box is selected
via the mouse, its gender attribute may be altered to male, female or
unknown by pressing the "1", "2" or "~" keys near the upper left of a
keyboard.  We used this attribution tool to assign gender labels to 40K+
facial bounding boxes.

One example of an image containing multiple gender assignments is displayed
in figure 1.  Purple [cyan] bounding boxes enclose female [male] faces.
Yellow bounding boxes mark persons for which we were significantly
uncertain about their sex.  As we attempted to accurately attribute
thousands of different people appearing in internet images, we were
surprised by how often it is difficult to determine gender from facial and
other appearance cues.  In particular, we found distinguishing baby boys
from baby girls to be nearly impossible if their clothing provided no clear
cultural hints.  In other cases, one can deduce that blurry patches in
images must correspond to human faces.  But such patches may contain too
little information for a gender label to be confidently assigned.  All such
faces marked with "unknown" genders are ignored in our classification
pipeline.

![FaceGender]({{site.url}}/blog/images/face_gender/training/image_03815_crowd_genders_01.png)
*Fig. 1. An image attributed with gender labels.*

The bounding boxes in figure 1 are snuggly wrapped around individual faces.
But valuable information is contained in hair styles, neckware and
upper-body clothing for gender determination.  So we double all bounding
box widths and heights.  The resulting human head regions come in a wide
variety of pixel sizes.  But a convolutional neural network requires
uniformly-sized imagery input.  In particular, the CNN we developed takes
image chips with 96x96 pixel size.  So chips larger than 96x96 were
subsampled, while chips smaller than 96x96 were superposed onto black
backgrounds.  Examples of head chips extracted from figure 1 and spatially
resized are presented in figure 2.

![FaceGender]({{site.url}}/blog/images/face_gender/training/training_chips_106x106.png)
*Fig. 2. Three female and three male head chips extracted from figure
1.  The chips' pixel sizes are doubled compared to their tightly-cropped
facial bounding box progenitors.*


- Incorporate Adience gender info (flickr selfies not as varied as our
images)
- Incorporate Iranian women
- Quote total number of male and female training samples.



![FaceGender]({{site.url}}/blog/images/face_gender/training/augmented_female_face.png)

![FaceGender]({{site.url}}/blog/images/face_gender/training/augmented_male_face.png)

*Fig. X. Representative examples of image augmentation.  Input female and
male training chips appear in the leftmost column of this figure.  Their
output variants are randomly translated, rotated, color-modulated and
flipped relative to the original images.*


![FaceGender]({{site.url}}/blog/images/face_gender/training/non_face_training_samples.png)
*Fig. X.  Training chip examples containing no human face content.*


![FaceGender]({{site.url}}/blog/images/face_gender/training/padded_cropped_net.png)
*Fig. X. Training architecture for CNN used to classify facial genders.*


![FaceGender]({{site.url}}/blog/images/face_gender/training/padded_accuracy_curves.png)
*Fig. X. CNN model accuracy plotted as a function of training epoch.  The
cyan curve is a temporally smoothed version of the raw accuracy values for
the training set which are colored in dark blue.  The CNN's accuracy on a
separate validation set is depicted by the red curve.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/padded_correct_female_classifications.png)
*Fig. X. Representative examples of test image chips correctly classified
by the CNN as female.*

![FaceGender]({{site.url}}/blog/images/face_gender/results/padded_correct_male_classifications.png)
*Fig. X. Representative examples of test image chips correctly classified
by the CNN as male.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/padded_unsure_classifications.png)
*Fig. X. Examples of test image chips for which the CNN was significantly
unsure about gender classification.  The top [bottom] row contains female
[male] image chips.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/padded_incorrect_classifications.png)
*Fig. X. Examples of test image chips for which the CNN assigned incorrect
gender classifications.  The top [bottom] row contains female [male] image chips.*


<table style="width:100%">
  <thead>
    <tr>
      <th style="text-align: center">Â </th>
      <th style="text-align: center">non- face</th>
      <th style="text-align: center">male face</th>
      <th style="text-align: center">female face</th>
      <th style="text-align: center">uncertain gender</th>
      <th style="text-align: center">% correct</th>
      <th style="text-align: center">% uncertain</th>
      <th style="text-align: center">% incorrect</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><strong>non-face</strong></td>
      <td style="text-align: center">1012</td>
      <td style="text-align: center">3</td>
      <td style="text-align: center">14</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">98.35</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1.65</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>male face</strong></td>
      <td style="text-align: center">51</td>
      <td style="text-align: center">1553</td>
      <td style="text-align: center">159</td>
      <td style="text-align: center">56</td>
      <td style="text-align: center">85.37</td>
      <td style="text-align: center">3.08</td>
      <td style="text-align: center">11.54</td>
    </tr>
    <tr>
      <td style="text-align: center"><strong>female gender</strong></td>
      <td style="text-align: center">25</td>
      <td style="text-align: center">216</td>
      <td style="text-align: center">1239</td>
      <td style="text-align: center">208</td>
      <td style="text-align: center">73.40</td>
      <td style="text-align: center">12.32</td>
      <td style="text-align: center">14.28</td>
    </tr>
  </tbody>
</table>


![FaceGender]({{site.url}}/blog/images/face_gender/results/good_all_faces.png)
*Fig. X. Example test images for which all faces were automatically localized 
and assigned correct gender labels.  Red [blue] bounding boxes enclose
female [male] faces.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/good_most_faces.png)
*Fig. X. Example test images for which all faces that were localized were
assigned correct gender labels.  Red [blue] bounding boxes enclose female
[male] faces, while the CNN assigned no gender labels to green bounding
boxes.  A few faces in these images were not localized.*

![FaceGender]({{site.url}}/blog/images/face_gender/results/OK_faces.png)
*Fig. X. Example test images for which all faces that were localized were
assigned correct gender labels.  Several faces in these images were not
localized.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/bad_faces.png)
*Fig. X. Example test images which which some faces that were localized
were assigned incorrect gender labels.  Red [blue] bounding boxes enclose
faces classified as female [red].  Some faces in these images were also not
localized.*

## References

1.  See "Detecting Faces via Deep Semantic Segmentation of Images" post
dated Jan 20, 2016.

2.  S. Yang, P. Luo, C.C. Loy and X. Tang, "WIDER FACE: A Face Detection
Benchmark", arXiv: 1511.06523v1 (2015).

3.  D. King, dlib C++ library, http://dlib.net/ml.html.

4.  L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy and A.L. Yuille,
*Semantic Image Segmentation with Deep Convolutional Nets and Fully
Connected CRFs*, arXiv:1412.7062 (2015).

5.  G. Papandreou, L.-C. Chen, K. Murphy and A. L. Yuille, Weakly and
semi-supervised learning of a DCNN for semantic image segmentation,
http://arxiv.org/1502.02734, (2015).

6.  See https://bitbucket.org/deeplab/deeplab-public/

7.  See http://caffe.berkeleyvision.orig.

*.  G. Levi and T. Hassncer, "Age and gender classification using
convolutional neural networks," CVPR 2015.
