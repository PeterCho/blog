---
layout: post
title:  "Classifying Gender via a Convolutional Neural Network for Faces"
date:   2016-08-09 12:00:00
categories: Deep Learning
---

## Gender training data 

In an earlier blog post, we presented a first-attempt at face detection via
deep semantic segmentation [1].  The initial results based upon 3K+
training images were qualitatively encouraging.  But we noted a number of
false negative and false positive results generated by our trained network.
Moreover, two or more faces appearing close together in an image were
sometimes merged together into a single segmentation region.  We also did
not quantify the performance of our first-attempt system.  In this blog
post, we return to the face detection problem and focus upon rectifying
these earlier shortcomings.

![FaceGender]({{site.url}}/blog/images/face_gender/training/image_03815_crowd_genders_01.png)
*Fig. X. An image attributed with gender labels.  Purple [cyan]
bounding boxes enclose female [male] faces.  Yellow bounding boxes mark
persons for which we were significantly uncertain about their genders.*

![FaceGender]({{site.url}}/blog/images/face_gender/training/training_chips_106x106.png)
*Fig. X. Representative examples of annotated training images.  Red and
cyan bounding boxes marking human faces and hands are best seen after
zooming into these images.*


![FaceGender]({{site.url}}/blog/images/face_gender/training/augmented_female_face.png)

![FaceGender]({{site.url}}/blog/images/face_gender/training/augmented_male_face.png)
*Fig. X. Representative examples of annotated training images.  Red and
cyan bounding boxes marking human faces and hands are best seen after
zooming into these images.*


![FaceGender]({{site.url}}/blog/images/face_gender/training/non_face_training_samples.png)
*Fig. X. Representative examples of annotated training images.  Red and
cyan bounding boxes marking human faces and hands are best seen after
zooming into these images.*


![FaceGender]({{site.url}}/blog/images/face_gender/training/padded_cropped_net.png)
*Fig. X. Representative examples of annotated training images.  Red and
cyan bounding boxes marking human faces and hands are best seen after
zooming into these images.*


![FaceGender]({{site.url}}/blog/images/face_gender/training/padded_accuracy_curves.png)
*Fig. X. Representative examples of annotated training images.  Red and
cyan bounding boxes marking human faces and hands are best seen after
zooming into these images.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/padded_correct_female_classifications.png)
*Fig. X. Representative examples of annotated training images.  Red and
cyan bounding boxes marking human faces and hands are best seen after
zooming into these images.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/padded_correct_male_classifications.png)
*Fig. X. Representative examples of annotated training images.  Red and
cyan bounding boxes marking human faces and hands are best seen after
zooming into these images.*

![FaceGender]({{site.url}}/blog/images/face_gender/results/padded_unsure_classifications.png)
*Fig. X. Representative examples of annotated training images.  Red and
cyan bounding boxes marking human faces and hands are best seen after
zooming into these images.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/padded_incorrect_classifications.png)
*Fig. X. Representative examples of annotated training images.  Red and
cyan bounding boxes marking human faces and hands are best seen after
zooming into these images.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/good_all_faces.png)
*Fig. X. Representative examples of annotated training images.  Red and
cyan bounding boxes marking human faces and hands are best seen after
zooming into these images.*

![FaceGender]({{site.url}}/blog/images/face_gender/results/good_most_faces.png)
*Fig. X. Representative examples of annotated training images.  Red and
cyan bounding boxes marking human faces and hands are best seen after
zooming into these images.*

![FaceGender]({{site.url}}/blog/images/face_gender/results/OK_faces.png)
*Fig. X. Representative examples of annotated training images.  Red and
cyan bounding boxes marking human faces and hands are best seen after
zooming into these images.*

![FaceGender]({{site.url}}/blog/images/face_gender/results/bad_faces.png)
*Fig. X. Representative examples of annotated training images.  Red and
cyan bounding boxes marking human faces and hands are best seen after
zooming into these images.*




## References

1.  See "Detecting Faces via Deep Semantic Segmentation of Images" post
dated Jan 20, 2016.

2.  S. Yang, P. Luo, C.C. Loy and X. Tang, "WIDER FACE: A Face Detection
Benchmark", arXiv: 1511.06523v1 (2015).

3.  D. King, dlib C++ library, http://dlib.net/ml.html.

4.  L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy and A.L. Yuille,
*Semantic Image Segmentation with Deep Convolutional Nets and Fully
Connected CRFs*, arXiv:1412.7062 (2015).

5.  G. Papandreou, L.-C. Chen, K. Murphy and A. L. Yuille, Weakly and
semi-supervised learning of a DCNN for semantic image segmentation,
http://arxiv.org/1502.02734, (2015).

6.  See https://bitbucket.org/deeplab/deeplab-public/

7.  See http://caffe.berkeleyvision.orig.

8.  M. Jaderberg, K. Simonyan, A. Vedaldi and A. Zisserman, *Synthetic Data
and Artifical Neural Networks for Natural Scene Text Recognition*, arXiv:
1406.2227v4 (2014).

9.  See "Localizing Text-in-the-Wild via Synthetic Phrase Generation and
Semantic Segmentation" post dated Apr 25, 2016.
