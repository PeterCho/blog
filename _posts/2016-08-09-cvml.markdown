---
layout: post
title:  "Classifying Gender via a Convolutional Neural Network for Faces"
date:   2016-08-09 12:00:00
categories: Deep Learning
---

## Gender training data 

In an earlier blog post, we presented a first-attempt at face detection via
deep semantic segmentation [1].  The initial results based upon 3K+
training images were qualitatively encouraging.  But we noted a number of
false negative and false positive results generated by our trained network.
Moreover, two or more faces appearing close together in an image were
sometimes merged together into a single segmentation region.  We also did
not quantify the performance of our first-attempt system.  In this blog
post, we return to the face detection problem and focus upon rectifying
these earlier shortcomings.

![FaceGender]({{site.url}}/blog/images/face_gender/training/image_03815_crowd_genders_01.png)
*Fig. X. An image attributed with gender labels.  Purple [cyan]
bounding boxes enclose female [male] faces.  Yellow bounding boxes mark
persons for which we were significantly uncertain about their genders.*


![FaceGender]({{site.url}}/blog/images/face_gender/training/training_chips_106x106.png)
*Fig. X. Three female and three male training chips extracted from figure
X.  The chips' pixel sizes are doubled compared to their tightly-cropped
facial bounding box progenitors.*


![FaceGender]({{site.url}}/blog/images/face_gender/training/augmented_female_face.png)

![FaceGender]({{site.url}}/blog/images/face_gender/training/augmented_male_face.png)

*Fig. X. Representative examples of image augmentation.  Input female and
male training chips appear in the leftmost column of this figure.  Their
output variants are randomly translated, rotated, color-modulated and
flipped relative to the original images.*


![FaceGender]({{site.url}}/blog/images/face_gender/training/non_face_training_samples.png)
*Fig. X.  Training chip examples containing no human face content.*


![FaceGender]({{site.url}}/blog/images/face_gender/training/padded_cropped_net.png)
*Fig. X. Training architecture for CNN used to classify facial genders.*


![FaceGender]({{site.url}}/blog/images/face_gender/training/padded_accuracy_curves.png)
*Fig. X. CNN model accuracy plotted as a function of training epoch.  The
cyan curve is a temporally smoothed version of the raw accuracy values for
the training set which are colored in dark blue.  The CNN's accuracy on a
separate validation set is depicted by the red curve.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/padded_correct_female_classifications.png)
*Fig. X. Representative examples of test image chips correctly classified
by the CNN as female.*

![FaceGender]({{site.url}}/blog/images/face_gender/results/padded_correct_male_classifications.png)
*Fig. X. Representative examples of test image chips correctly classified
by the CNN as male.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/padded_unsure_classifications.png)
*Fig. X. Examples of test image chips for which the CNN was significantly
unsure about gender classification.  The top [bottom] row contains female
[male] image chips.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/padded_incorrect_classifications.png)
*Fig. X. Examples of test image chips for which the CNN assigned incorrect
gender classifications.  The top [bottom] row contains female [male] image chips.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/good_all_faces.png)
*Fig. X. Example test images for which all faces were automatically localized 
and assigned correct gender labels.  Red [blue] bounding boxes enclose
female [male] faces.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/good_most_faces.png)
*Fig. X. Example test images for which all faces that were localized were
assigned correct gender labels.  Red [blue] bounding boxes enclose female
[male] faces, while the CNN assigned no gender labels to green bounding
boxes.  A few faces in these images were not localized.*

![FaceGender]({{site.url}}/blog/images/face_gender/results/OK_faces.png)
*Fig. X. Example test images for which all faces that were localized were
assigned correct gender labels.  Several faces in these images were not
localized.*


![FaceGender]({{site.url}}/blog/images/face_gender/results/bad_faces.png)
*Fig. X. Example test images which which some faces that were localized
were assigned incorrect gender labels.  Red [blue] bounding boxes enclose
faces classified as female [red].  Some faces in these images were also not
localized.*


## References

1.  See "Detecting Faces via Deep Semantic Segmentation of Images" post
dated Jan 20, 2016.

2.  S. Yang, P. Luo, C.C. Loy and X. Tang, "WIDER FACE: A Face Detection
Benchmark", arXiv: 1511.06523v1 (2015).

3.  D. King, dlib C++ library, http://dlib.net/ml.html.

4.  L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy and A.L. Yuille,
*Semantic Image Segmentation with Deep Convolutional Nets and Fully
Connected CRFs*, arXiv:1412.7062 (2015).

5.  G. Papandreou, L.-C. Chen, K. Murphy and A. L. Yuille, Weakly and
semi-supervised learning of a DCNN for semantic image segmentation,
http://arxiv.org/1502.02734, (2015).

6.  See https://bitbucket.org/deeplab/deeplab-public/

7.  See http://caffe.berkeleyvision.orig.

8.  M. Jaderberg, K. Simonyan, A. Vedaldi and A. Zisserman, *Synthetic Data
and Artifical Neural Networks for Natural Scene Text Recognition*, arXiv:
1406.2227v4 (2014).

9.  See "Localizing Text-in-the-Wild via Synthetic Phrase Generation and
Semantic Segmentation" post dated Apr 25, 2016.
