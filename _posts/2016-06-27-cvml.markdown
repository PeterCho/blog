---
layout: post
title:  "Localizing Faces via Data Augmentation and Instance Segmentation
of Images"
date:   2016-06-27 12:00:0
categories: Deep Learning
---

## Faces and hands training data

In an earlier blog post, we presented a first attempt at face detection via
deep semantic segmentation [1].  The initial results based upon 3K+
training images were qualitatively encouraging.  But we noted a number of
false negative and false positive results generated by our trained network.
Moreover, two or more faces appearing close together in an image were
sometimes merged together within a single segmentation region.  And we did
not previously quantify the classifier's performance.  In this blog post,
we return to the face detection problem and focus upon rectifying these
earlier shortcomings.

We start by increasing our training set size.  This time we work with 11491
internet images which were intentionally chosen to exhibit variety along
multiple dimensions.  A random subset of 700 images was reserved for
validation, and another random subset of 700 images was held out for
testing.  The remaining 10K+ images were used for training.

8671 images contain a total of 36196 bounding boxes wrapped around human
faces.  As figure X illustrates, the annotated faces belong to people with
varying attributes (e.g. gender, age, ethnicity) performing different
activities (e.g. eating, running, protesting) in disparate settings
(e.g. restaurants, farms, business meetings).  Faces occur in different
poses (e.g. straight towards camera, profile, downwards), and several are
partially occluded by objects (e.g. eyeglasses, masks, cigarettes).  As
figure X tabulates, the face bounding boxes span a range of pixel widths.
Moreover, some of our face data intentionally come from "2D" sources such
as photographs, paintings and drawings.

![FaceLocalization]({{site.url}}/blog/images/face_localization/training_images/training_montage.png)
*Fig. X. Representative examples of annotated training images.  Human faces
and hands are marked by red and cyan bounding boxes.*


|  Bbox   	| Lower bbox   	| Upper bbox   	|
|  percentage  	| pixel width   | pixel width  	| 
|:-------------:|:-------------:|:-------------:|
|   0-10	|  0 		| 7.7  		|
|   10-20	|  7.7	 	| 12.9  	|
|   20-30 	|  12.9		| 18.7  	| 
|   30-40 	|  18.7 	| 24.9  	|
|   40-50	|  24.9 	| 31.2  	| 
|   50-60	|  31.2 	| 39.2  	| 
|   60-70	|  39.2 	| 50.8	  	| 
|   70-80	|  50.8 	| 67.9  	| 
|   80-90	|  67.9		| 100.3  	| 
|   90-100	|  100.3	| Infinity  	| 

*Fig. X.  Pixel width ranges for 36K+ face bounding boxes listed as functions of
cumulative bounding box percentages.*

As we generated facial bounding boxes using Davis King's image labeling
tool [ref], we observed that humans frequently put their hands on their
faces (see figure XX).  Indeed, XX percent of our 36K face bounding boxes
are overlapped by hand pixels.  We observed that semantic segmentation
networks trained with such "contaminated" face data then often mistakenly
classify hands as faces.  So we labeled hands as well as faces in our
imagery corpus.  Hands are inherently more deformable than faces, and their
appearance within images is significantly more varied.  As the image
labeling tool only generates rectangles rather than arbitrary polygons, we
sometimes placed more than one bounding box around different parts of a
hand in order to trace it with higher fidelity.  7259 of our 11491 images
contain some hand content.

![FaceLocalization]({{site.url}}/blog/images/face_localization/training_images/hands_on_faces.png)
*Fig. X. Examples of hands overlapping faces.*








![FaceLocalization]({{site.url}}/blog/images/face_localization/training_images/animal_faces.png)
*Fig. X. Negative examples of human faces and hands intentionally include 
animal pictures.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/data_augmentation/image_00692.jpg)
*Fig. X. A representative training image containing multiple face and hand
bounding boxes.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/data_augmentation/output_6x3_tile_montage.jpg)
*Fig. X. Examples of training tiles extracted around face and hand boxes in
figure X.  Note variations in the image chips' translations, colorings and
horizontal parities.*



## Face instance segmentation

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/friends/image_04084.jpg)
*Fig. X. A "Friends" image within our testing set.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/friends/double_full_half_ccs.png)
*Fig. X.  Pixel-level semantic segmentation of faces and hands within
the test image (upper right) and its double-sized (left) and
half-sized (lower right) versions.  Colored bounding boxes indicate
connected components within these segmentation masks.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/friends/double_full_half_scores.png)
*Fig. X.  Pixel-level scores for semantic segmentation results of figure X.
Warmer colors indicate higher confidences than cooler colors.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/friends/flattened_segs_04084.png)
*Fig. X.  Semantic segmentation results consolidated across image scales.*


![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/friends/double_full_half_quads.png)
*Fig. X.  Face quadrant segmentation results at original-sized (upper
right), double-sized (left) and half-sized (lower right) image scales.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/friends/quad_centers_04084_0.png)
*Fig. X.  White bounding box midpoints mark centers for individual faces.
Purple bounding boxes enclose the original facial connected components as
in figure XX.*


![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/friends/segmented_image_04084.png)
*Fig. X.  Final set of localized faces and hands are indicated by orange
and green bounding boxes*.

## Face localization performance results

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/quadrant_masks/montage_image_01712__segmented_image_01712.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/quadrant_masks/montage_image_00936__segmented_image_00936.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/quadrant_masks/montage_image_01750__segmented_image_01750.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/quadrant_masks/montage_image_00336___doublesized_segmented_image_00336.jpg)

*Fig. X.  Face quadrant segmentations for 4 representative images*.



![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_00014___segmented_image_00014.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_02124___segmented_image_02124.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_09626___segmented_image_09626.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_05893___segmented_image_05893.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_02192___segmented_image_02192.jpg)


*Fig. X.   Faces and hands localized in images containing groups of people.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_08754___segmented_image_08754.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_09561___segmented_image_09561.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_03836___segmented_image_03836.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_02269___segmented_image_02269.jpg)

*Fig. X.   Faces and hands localized in images containing crowds of people.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_10208___segmented_image_10208.jpg)

*Fig. X.   Face localized in an image of a black-and-white photograph.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_05206___segmented_image_05206.jpg)

*Fig. X.   Face localized in an image of an oil painting.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_05236___segmented_image_05236.jpg)

*Fig. X.   Face localized in an image of a line drawing.*


![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/bad_results/false_negatives.png)

*Fig. X.   Examples of partially or completely missed faces.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/bad_results/false_positives.png)

*Fig. X.   Human face false alarms.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/bad_results/wrong_bboxes.png)

*Fig. X.  One bounding box incorrectly enclosing two faces (LHS) and three bounding
boxes incorrectly overlapping one face (RHS).*






## References

1.  See "Detecting Faces via Deep Semantic Segmentation of Images" post
dated Jan 20, 2016.

1.  M. Jaderberg, K. Simonyan, A. Vedaldi and A. Zisserman, *Synthetic Data
and Artifical Neural Networks for Natural Scene Text Recognition*, arXiv:
1406.2227v4 (2014).

2.  See www.imagemagick.org/Usage/text/ .

3.  L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy and A.L. Yuille,
*Semantic Image Segmentation with Deep Convolutional Nets and Fully
Connected CRFs*, arXiv:1412.7062 (2015).


