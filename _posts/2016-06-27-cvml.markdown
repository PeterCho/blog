---
layout: post
title:  "Localizing Faces via Data Augmentation and Instance Segmentation
of Images"
date:   2016-06-27 12:00:0
categories: Deep Learning
---

## Faces and hands training data

In an earlier blog post, we presented a first attempt at face detection via
deep semantic segmentation [1].  The initial results based upon 3K+
training images were qualitatively encouraging.  But we noted a number of
false negative and false positive results generated by our trained network.
Moreover, two or more faces appearing close together in an image were
sometimes merged together within a single segmentation region.  And we did
not previously quantify the classifier's performance.  In this blog post,
we return to the face detection problem and focus upon rectifying these
earlier shortcomings.

We start by increasing our training set size.  This time we work with 11491
internet images which were intentionally chosen to exhibit variety along
multiple dimensions.  A random subset of 700 images was reserved for
validation, and another random subset of 700 images was held out for
testing.  The remaining 10K+ images were used for training.

8671 images contain a total of 36196 bounding boxes wrapped around human
faces.  As figure X illustrates, the annotated faces belong to people with
varying attributes (e.g. gender, age, ethnicity) performing different
activities (e.g. eating, running, protesting) in disparate settings
(e.g. restaurants, farms, business meetings).  Faces occur in different
poses (e.g. straight towards camera, profile, downwards), and several are
partially occluded by objects (e.g. eyeglasses, masks, cigarettes).  As
figure X tabulates, the face bounding boxes span a range of pixel widths.
Moreover, some of our face data intentionally come from "2D" sources such
as photographs, paintings and drawings.

![FaceLocalization]({{site.url}}/blog/images/face_localization/training_images/training_montage.png)
*Fig. X. Representative examples of annotated training images.  Human faces
and hands are marked by red and cyan bounding boxes.*


|  Bbox   	| Lower bbox   	| Upper bbox   	|
|  percentage  	| pixel width   | pixel width  	| 
|:-------------:|:-------------:|:-------------:|
|   0-10	|  0 		| 7.7  		|
|   10-20	|  7.7	 	| 12.9  	|
|   20-30 	|  12.9		| 18.7  	| 
|   30-40 	|  18.7 	| 24.9  	|
|   40-50	|  24.9 	| 31.2  	| 
|   50-60	|  31.2 	| 39.2  	| 
|   60-70	|  39.2 	| 50.8	  	| 
|   70-80	|  50.8 	| 67.9  	| 
|   80-90	|  67.9		| 100.3  	| 
|   90-100	|  100.3	| Infinity  	| 

*Fig. X.  Pixel width ranges for 36K+ face bounding boxes listed as functions of
cumulative bounding box percentages.*

As we generated facial bounding boxes using Davis King's image labeling
tool [ref], we observed that humans frequently put their hands on their
faces (see figure XX).  Indeed, XX percent of our 36K+ face bounding boxes
are overlapped by bare hand content.  Semantic segmentation networks
trained with such "contaminated" face data often mistakenly classify hands
as faces.  So we decided to label hands as well as faces in our imagery
corpus.  But we only annotated bare hands which share similar skin tones to
faces and ignored hands covered by opaque gloves.  7259 of our 11491 images
contain bare hand content.

Since hands are inherently more deformable than faces, their appearance
within images is significantly more varied.  As the image labeling tool
only enables objects to be annotated by rectangles rather than arbitrary
polygons, we sometimes used more than one bounding box to trace different
parts of a hand with higher fidelity than a single rectangle could achieve.
In contrast, we always labeled a single face with a single bounding box.

![FaceLocalization]({{site.url}}/blog/images/face_localization/training_images/hands_on_faces.png)
*Fig. X. Examples of annotated images with overlapping face and hand
bounding boxes.*

Among our training, validation and testing images, O(2K) have neither human
faces nor hands.  Figure XX illustrates a few of these negative examples.
Some contain zero human content.  Others display body parts such as backs
of heads, torsos and legs whose shapes or colorings could be confused with
faces or hands.  We also intentionally included several pictures of animal
faces into our imagery corpus which a classifier should learn to
distinguish from human faces.  Moreover, we made sure to incorporate
photos, paintings and line drawings of non-human faces so that a classifier
would not always fire on such 2D representations.





![FaceLocalization]({{site.url}}/blog/images/face_localization/training_images/negative_examples.png)
*Fig. X. Negative examples which contain no human face or
hand content.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/data_augmentation/image_00692.jpg)
*Fig. X. A representative training image containing multiple face and hand
bounding boxes.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/data_augmentation/output_6x3_tile_montage.jpg)
*Fig. X. Examples of training tiles extracted around face and hand boxes in
figure X.  Note variations in the image chips' translations, colorings and
horizontal parities.*



## Face instance segmentation

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/friends/image_04084.jpg)
*Fig. X. A "Friends" image within our testing set.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/friends/double_full_half_ccs.png)
*Fig. X.  Pixel-level semantic segmentation of faces and hands within
the test image (upper right) and its double-sized (left) and
half-sized (lower right) versions.  Colored bounding boxes indicate
connected components within these segmentation masks.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/friends/double_full_half_scores.png)
*Fig. X.  Pixel-level scores for semantic segmentation results of figure X.
Warmer colors indicate higher confidences than cooler colors.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/friends/flattened_segs_04084.png)
*Fig. X.  Semantic segmentation results consolidated across image scales.*


![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/friends/double_full_half_quads.png)
*Fig. X.  Face quadrant segmentation results at original-sized (upper
right), double-sized (left) and half-sized (lower right) image scales.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/friends/quad_centers_04084_orange.png)
*Fig. X.  Midpoints of white rectangles mark centers for individual faces.
Orange bounding boxes enclose the original facial connected components as in figure XX.*


![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/friends/segmented_image_04084.png)
*Fig. X.  Final set of localized faces and hands are indicated by orange
and green bounding boxes*.

## Face localization performance results

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/quadrant_masks/montage_image_01712___segmented_image_01712.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/quadrant_masks/montage_image_00936___segmented_image_00936.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/quadrant_masks/montage_image_01750___segmented_image_01750.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/quadrant_masks/montage_image_00336___doublesized_segmented_image_00336.jpg)

*Fig. X.  Face quadrant segmentations for 4 representative images*.



![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_00014___segmented_image_00014.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_02124___segmented_image_02124.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_09626___segmented_image_09626.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_05893___segmented_image_05893.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_02192___segmented_image_02192.jpg)


*Fig. X.   Faces and hands localized in images containing groups of people.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_08754___segmented_image_08754.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_09561___segmented_image_09561.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_03836___segmented_image_03836.jpg)

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_02269___segmented_image_02269.jpg)

*Fig. X.   Faces and hands localized in images containing crowds of people.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_10208___segmented_image_10208.jpg)

*Fig. X.   Face localized in an image of a black-and-white photograph.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_05206___segmented_image_05206.jpg)

*Fig. X.   Face localized in an image of an oil painting.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/good_results/montage_image_05236___segmented_image_05236.jpg)

*Fig. X.   Face localized in an image of a line drawing.*


![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/bad_results/false_negatives.png)

*Fig. X.   Examples of partially or completely missed faces.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/bad_results/false_positives.png)

*Fig. X.   Human face false alarms.*

![FaceLocalization]({{site.url}}/blog/images/face_localization/testing_images/bad_results/wrong_bboxes.png)

*Fig. X.  One bounding box incorrectly enclosing two faces (LHS) and three bounding
boxes incorrectly overlapping one face (RHS).*






## References

1.  See "Detecting Faces via Deep Semantic Segmentation of Images" post
dated Jan 20, 2016.

1.  M. Jaderberg, K. Simonyan, A. Vedaldi and A. Zisserman, *Synthetic Data
and Artifical Neural Networks for Natural Scene Text Recognition*, arXiv:
1406.2227v4 (2014).

2.  See www.imagemagick.org/Usage/text/ .

3.  L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy and A.L. Yuille,
*Semantic Image Segmentation with Deep Convolutional Nets and Fully
Connected CRFs*, arXiv:1412.7062 (2015).


