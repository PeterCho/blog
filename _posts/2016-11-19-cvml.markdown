---
layout: post
title:  "Solving Mazes via Deep Reinforcement Learning"
date:   2016-11-19 12:00:00
categories: Deep Learning
use_math: true
---

## Reinforcement learning

Since the breakthrough paper of Krizhevsky et al in 2012 [1], convolution
neural networks have repeatedly been demonstrated to perform a growing list
of useful image processing tasks. 


$$ a^2+b^2 = c^2 $$

Let's test some inline math $x$, $y$, $x_1$, $y_1$.

Test a display math:
$$
   |\psi_1\rangle = a|0\rangle + b|1\rangle
$$
Is it O.K.?

Test a display math with equation number:
$$
  \begin{align}
    |\psi_1\rangle &= a|0\rangle + b|1\rangle \\
    |\psi_2\rangle &= c|0\rangle + d|1\rangle
  \end{align}
$$
Is it O.K.?

## Q learning

Traditional backpropagation iteratively applies gradients to adjust the
weights of a neural network and minimize discrepancies between fixed input
image labels and their classifier-generated counterparts.  But

![MazeRL]({{site.url}}/blog/images/maze_rl/nondeepQ/doublepadded_empty_maze.png)
*Fig. XX. A 10x10 maze generated recursively.*

![MazeRL]({{site.url}}/blog/images/maze_rl/nondeepQ/padded_Qmap_score_history.png)
*Fig. XX. Fractional correct maze score plotted versus episode number
during reinforcement learning.*

<a href="http://www.youtube.com/watch?feature=player_embedded&v=QXr8LJHTpNE"
target="_blank"><img src="http://img.youtube.com/vi/QXr8LJHTpNE/0.jpg"
alt="IMAGE ALT TEXT HERE" width="720" height="480" border="10" /></a>
*Fig. XX.  Movie illustrating solving the 10x10 maze in figure XX tabular Q learning .  Click on image above to play video.*




## Deep Q learning

The numbers of nodes in each layer of a CNN are freely chosen
hyperparameters.  We let fully connected layers 5 and 6 in Model II contain
256 neurons.  FC5 and FC6 activation values thus form 256-dimensional
global descriptors for input test images.  But many of the FC5 and FC6
descriptor coordinates are strongly correlated.  So the genuine dimensions

![MazeRL]({{site.url}}/blog/images/maze_rl/deepQ/padded_log10_losses_history.png)
*Fig. XX. Log base 10 of loss function plotted versus episode number during
deep Q learning.*

![MazeRL]({{site.url}}/blog/images/maze_rl/deepQ/padded_Qmap_score_history.png)
*Fig. XX. Fractional correct maze score plotted versus episode number
during deep Q learning.*

<a href="http://www.youtube.com/watch?feature=player_embedded&v=KW0X0gB1B2I"
target="_blank"><img src="http://img.youtube.com/vi/KW0X0gB1B2I/0.jpg"
alt="IMAGE ALT TEXT HERE" width="720" height="480" border="10" /></a>
*Fig. XX.  Movie illustrating solving of a 10x10 maze via deep Q learning .  Click on image above to play video.*


![MazeRL]({{site.url}}/blog/images/maze_rl/deepQ/trained_padded_weights.png)
*Fig. XX. Visualization of trained weights in first layer of neural
network.*

## References

*.  [D. Silver, "Deep Reinforcement Learning", ICLR 2015.](http://www.iclr.cc/lib/exe/fetch.php?media=iclr2015:silver-iclr2015.pdf)

2.  See ["Classifying Gender in Internet Images via a Convolutional Neural
Network for Faces" (Aug 2016)](http://petercho.github.io/blog//deep/learning/2016/08/09/cvml.html) entry in this blog.

