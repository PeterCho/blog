---
layout: post
title:  "Solving Mazes via Deep Q Learning"
date:   2016-11-19 12:00:00
categories: Deep Learning
---

## Reinforcement learning

Since the breakthrough paper of Krizhevsky et al in 2012 [1], convolution
neural networks have repeatedly been demonstrated to perform a growing list
of useful image processing tasks. 

![CNNVis]({{site.url}}/blog/images/cnn_vis/rescaled_training_images.jpg)
*Fig. 1. Three female and three male head chips extracted from the internet
image in figure 1 of our previous blog entry [2].  These chips are unpadded
and rescaled versions of those appearing in figure 2 of [2].*

## Q learning

Traditional backpropagation iteratively applies gradients to adjust the
weights of a neural network and minimize discrepancies between fixed input
image labels and their classifier-generated counterparts.  But

## Deep Q learning

The numbers of nodes in each layer of a CNN are freely chosen
hyperparameters.  We let fully connected layers 5 and 6 in Model II contain
256 neurons.  FC5 and FC6 activation values thus form 256-dimensional
global descriptors for input test images.  But many of the FC5 and FC6
descriptor coordinates are strongly correlated.  So the genuine dimensions

## References

1.  [A. Krizhevsky, I. Sutskever and G.E. Hinton, "ImageNet Classification
with Deep Convolutional Neural Networks", NIPS (2012).](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

2.  See ["Classifying Gender in Internet Images via a Convolutional Neural
Network for Faces" (Aug 2016)](http://petercho.github.io/blog//deep/learning/2016/08/09/cvml.html) entry in this blog.
